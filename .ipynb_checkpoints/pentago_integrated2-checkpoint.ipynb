{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from helper_func import *\n",
    "import pickle\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pentago:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state = None):\n",
    "        \"\"\"Initializes the class reservation\"\"\"\n",
    "        #print('initializing')\n",
    "        \n",
    "        if state == None:\n",
    "            self.state = state = np.zeros((6,6), dtype=np.int)\n",
    "        self.history = []\n",
    "        self.winner = None\n",
    "        self.gameover = False\n",
    "        self.player_turn = 1\n",
    "    \n",
    "    def current_board_state(self):\n",
    "        # need to return a copy or bad stuff happens\n",
    "        return copy.copy(self.state)\n",
    "    \n",
    "    def game_history(self, player, move, cuad, rotatation):\n",
    "        self.history.append((boardstate_to_ideal_key(self.state), player, move, cuad, rotatation))\n",
    "        #return self.history\n",
    "\n",
    "    def find_winner(self, board_state):\n",
    "        player1_win = False\n",
    "        player_min1_win = False\n",
    "        diagonal1 = board_state.diagonal()\n",
    "        diagonal2 = np.fliplr(board_state).diagonal()\n",
    "        winning_slices =  np.vstack([board_state[1:,:].T, board_state[:-1,:].T, # all columns\n",
    "                              board_state[:,1:], board_state[:,:-1], # all rows\n",
    "                              diagonal1[1:], diagonal1[:-1], # diagonal 1\n",
    "                              diagonal2[1:],diagonal2[1:], # diagonal 2\n",
    "                              board_state.diagonal(offset=1), board_state.diagonal(offset=-1), # diagonal offsets \n",
    "                              np.fliplr(board_state).diagonal(offset=1), np.fliplr(board_state).diagonal(offset=-1)] ) # diagonal offsets\n",
    "        sums = np.dot(winning_slices, np.array([1,1,1,1,1]))\n",
    "        if 5 in sums: player1_win = True\n",
    "        if -5 in sums: player_min1_win = True\n",
    "        if player1_win == True or player_min1_win == True:\n",
    "           # print(\"Player 1 winner?\", player1_win, \"Player -1 winner?\", player_min1_win)\n",
    "            self.gameover = True\n",
    "            if player1_win == True:\n",
    "                self.winner = 1\n",
    "            elif player_min1_win ==True:\n",
    "                self.winner = -1\n",
    "            self.history.append(self.winner)\n",
    "        return \"Win\"\n",
    "\n",
    "    def check_gameover(self):\n",
    "        if not 0 in self.state:\n",
    "              self.gameover = True\n",
    "              print(\"The game board is full!\")\n",
    "        \n",
    "    def full_move(self, move, cuad, direction, player, dtype=np.int):\n",
    "        if player != self.player_turn:\n",
    "            print( \"error, wrong player turn. No move taken.\")\n",
    "            return 'Error, wrong player turn.'\n",
    "        self.state = fullmove(self.state,move, cuad, direction, player)\n",
    "\n",
    "\n",
    "        self.game_history(move, player, cuad, direction)\n",
    "        self.find_winner(self.state) #return in find_winner if a winner is found\n",
    "        self.check_gameover() #return in check_gameover\n",
    "        if player == 1:\n",
    "            self.player_turn = -1\n",
    "        else:\n",
    "            self.player_turn = 1\n",
    "        #print('Successful Move')\n",
    "        return self.state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_table:\n",
    "\n",
    "    def __init__(self,length=0, games_played=0):\n",
    "        \"\"\"Initializes the class reservation\"\"\"\n",
    "        self.time = datetime.now()\n",
    "        self.length = length\n",
    "        self.q_dict = {}\n",
    "        self.games_played = games_played\n",
    "\n",
    "  #def time(self):\n",
    "    #self.time = time\n",
    "\n",
    "    def length(self):\n",
    "        self.length += 1\n",
    "    #self.length = length  \n",
    "    \n",
    "    def get_q_value(self, boardstate):\n",
    "        return self.q_dict.get(boardstate, (0, 0))\n",
    "    \n",
    "    def update_q_value(self, boardstate, new_val, update_function = None):\n",
    "        q_val, n = self.get_q_value(boardstate) \n",
    "        if update_function:\n",
    "            #print('using custom function')\n",
    "            self.q_dict[boardstate] = update_function(q_val, n, new_val)\n",
    "        else:\n",
    "            self.q_dict[boardstate] = [new_val, n+1]\n",
    "        return self.q_dict[boardstate]\n",
    "    \n",
    "    def update_post_game(self, history, update_fn):\n",
    "        winner = history[-1]\n",
    "        \n",
    "        for boardposition in history[-2::-1]:\n",
    "            key = boardposition[0]\n",
    "            #print(key, winner)\n",
    "            self.update_q_value(key, winner, update_fn)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(q, n, nn):\n",
    "    #print('here',q, n, nn, 'end')\n",
    "    #q, n = cv\n",
    "    return (q*n+nn)/(n+1), n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dampen_func(q, n, nn):\n",
    "    #print('here',q, n, nn, 'end')\n",
    "    #q, n = cv\n",
    "    return (q*(n+1)+nn)/(n+2), n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "class qtable_agent:\n",
    "    \n",
    "    def __init__(self, player = 1, epsilon = 1, epsilon_decay = .99995, epsilon_min = .5, q_table = q_table()):\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.q_table = q_table\n",
    "        self.player = player\n",
    "        self.epsilon_min = epsilon_min\n",
    "        \n",
    "            \n",
    "    def get_avail_moves(self,boardstate):\n",
    "        \"\"\"\n",
    "        This method creates a list with available spaces in the board and combination of quadrant and rotation\n",
    "        The input is the board state (6x6) numpy array\n",
    "        \"\"\"\n",
    "        x = np.where(boardstate == 0)\n",
    "        #print(x)\n",
    "        available_positions_for_placement = list(zip(x[0], x[1]))\n",
    "        \n",
    "        # all available positions (p), quadrants(q), rotations(r)\n",
    "        available_moves = [(p,q,r) for p in available_positions_for_placement for q in [1,2,3,4] for r in [-1,1]]\n",
    "        #print(len(available_moves))\n",
    "        return available_moves\n",
    "    \n",
    "    def get_possible_next_boardstates(self, boardstate):\n",
    "        next_possible_boardstates = defaultdict(list)\n",
    "        for move in self.get_avail_moves(boardstate):\n",
    "            possible_boardstate = fullmove(boardstate,*move, self.player)\n",
    "            key = boardstate_to_ideal_key(possible_boardstate)\n",
    "            #print(key)\n",
    "            next_possible_boardstates[key].append(move)\n",
    "            \n",
    "        return next_possible_boardstates\n",
    "    \n",
    "    def make_move(self, game):\n",
    "        \n",
    "        # get the current boardstate from the pentago class\n",
    "        boardstate = game.current_board_state()\n",
    "        \n",
    "        # get possible next possible boardstates\n",
    "        next_possible_boardstates = self.get_possible_next_boardstates(boardstate)\n",
    "        key_list = list(next_possible_boardstates.keys())\n",
    "        \n",
    "        # determine if to take random move\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            random_bs = random.choice(key_list)\n",
    "            random_mv = next_possible_boardstates[random_bs][0]\n",
    "            \n",
    "            game.full_move(*random_mv,self.player)\n",
    "            \n",
    "        else:\n",
    "            #print(\"not random\", self.player)\n",
    "            q_values_list = [self.q_table.get_q_value(bs)[0]*self.player for bs in key_list] # *player flips the q's for -1 player to allow max calc\n",
    "            #print(q_values_list)\n",
    "            \n",
    "            # get random index of a max value\n",
    "            max_q = (max(q_values_list))\n",
    "            index_of_all_max = [i for i in range(len(q_values_list)) if q_values_list[i] == max_q]\n",
    "            random_max_q_index = random.choice(index_of_all_max)\n",
    "            \n",
    "            mv_to_take = next_possible_boardstates[key_list[random_max_q_index]][0]\n",
    "            game.full_move(*mv_to_take, self.player)\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay \n",
    "        else:\n",
    "            self.epsilon = self.epsilon_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_sim(n_games, agent1, agent2, qtables_to_update = [], update_cadence = 1):\n",
    "    game_times = []\n",
    "    q_dict_update_times = []\n",
    "    winner_list = []\n",
    "    \n",
    "    for n in range(n_games):\n",
    "        print('game', n, end = ' ')\n",
    "        game_start = time.time()\n",
    "        g = pentago() # initialize game\n",
    "        \n",
    "        while g.gameover == False:\n",
    "            agent1.make_move(g)\n",
    "            if g.gameover ==True:\n",
    "                break\n",
    "            agent2.make_move(g)\n",
    "            \n",
    "        game_times.append(time.time()-game_start)\n",
    "        \n",
    "        # check for winner and update q_table(s)\n",
    "        if g.winner:\n",
    "            winner_list.append(g.winner)\n",
    "            print('winner: ', g.winner)\n",
    "            if n%update_cadence == 0:\n",
    "                # update time\n",
    "                update_start = time.time()\n",
    "                for q_tab in qtables_to_update:\n",
    "                    q_tab.update_post_game(g.history, dampen_func)\n",
    "                q_dict_update_times.append(time.time()-update_start)\n",
    "        else:\n",
    "            print('No winner!')\n",
    "    # end of simulation runs, save q_table(s) to disk\n",
    "    qt_num = 1\n",
    "    time_str = str(datetime.now())[:19].replace(':','_')\n",
    "    for q_tab in qtables_to_update:\n",
    "        with open(f'q_table{qt_num}_'+time_str+'.pickle', 'wb') as file:\n",
    "            pickle.dump(q_tab, file, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "        qt_num += 1\n",
    "    \n",
    "    print('game_times:', game_times)\n",
    "    print('q_dict_update_times:', q_dict_update_times)\n",
    "    print('winners:', winner_list)\n",
    "    winner1 = len([w for w in winner_list if w == 1])\n",
    "    winner_min1 = len([w for w in winner_list if w == -1])\n",
    "    print(\"Player 1 wins: \", winner1)\n",
    "    print(\"Player -1 wins:\", winner_min1)\n",
    "    \n",
    "    return game_times, q_dict_update_times, winner_list\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note you will overwrite this q_table and agents if you run this cell again.    Verify you won't lose your data!\n",
    "qtable1 = q_table()  \n",
    "agent1 = qtable_agent(player = 1,  q_table=qtable1)\n",
    "agent2 = qtable_agent(player = -1, q_table=qtable1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game 0 winner:  1\n",
      "game 1 winner:  -1\n",
      "game 2 The game board is full!\n",
      "No winner!\n",
      "game 3 winner:  1\n",
      "game 4 winner:  -1\n",
      "game 5 winner:  -1\n",
      "game 6 winner:  1\n",
      "game 7 winner:  -1\n",
      "game 8 winner:  -1\n",
      "game 9 winner:  -1\n",
      "game 10 winner:  -1\n",
      "game 11 winner:  1\n",
      "game 12 winner:  1\n",
      "game 13 winner:  1\n",
      "game 14 winner:  -1\n",
      "game 15 winner:  1\n",
      "game 16 The game board is full!\n",
      "No winner!\n",
      "game 17 winner:  1\n",
      "game 18 winner:  1\n",
      "game 19 winner:  -1\n",
      "game 20 winner:  -1\n",
      "game 21 winner:  -1\n",
      "game 22 winner:  1\n",
      "game 23 winner:  1\n",
      "game 24 winner:  1\n",
      "game 25 winner:  -1\n",
      "game 26 winner:  1\n",
      "game 27 winner:  1\n",
      "game 28 winner:  -1\n",
      "game 29 The game board is full!\n",
      "No winner!\n",
      "game 30 winner:  1\n",
      "game 31 winner:  -1\n",
      "game 32 winner:  1\n",
      "game 33 winner:  1\n",
      "game 34 The game board is full!\n",
      "winner:  -1\n",
      "game 35 winner:  1\n",
      "game 36 winner:  1\n",
      "game 37 The game board is full!\n",
      "winner:  1\n",
      "game 38 winner:  -1\n",
      "game 39 winner:  -1\n",
      "game 40 winner:  1\n",
      "game 41 The game board is full!\n",
      "No winner!\n",
      "game 42 winner:  1\n",
      "game 43 The game board is full!\n",
      "No winner!\n",
      "game 44 winner:  1\n",
      "game 45 winner:  -1\n",
      "game 46 winner:  1\n",
      "game 47 winner:  1\n",
      "game 48 winner:  -1\n",
      "game 49 winner:  1\n",
      "game 50 winner:  1\n",
      "game 51 winner:  -1\n",
      "game 52 winner:  -1\n",
      "game 53 winner:  1\n",
      "game 54 winner:  1\n",
      "game 55 winner:  1\n",
      "game 56 winner:  1\n",
      "game 57 winner:  1\n",
      "game 58 winner:  1\n",
      "game 59 winner:  1\n",
      "game 60 winner:  1\n",
      "game 61 winner:  1\n",
      "game 62 winner:  1\n",
      "game 63 winner:  1\n",
      "game 64 winner:  -1\n",
      "game 65 winner:  1\n",
      "game 66 winner:  -1\n",
      "game 67 winner:  1\n",
      "game 68 winner:  1\n",
      "game 69 The game board is full!\n",
      "No winner!\n",
      "game 70 winner:  1\n",
      "game 71 winner:  -1\n",
      "game 72 winner:  1\n",
      "game 73 winner:  -1\n",
      "game 74 winner:  1\n",
      "game 75 winner:  -1\n",
      "game 76 winner:  -1\n",
      "game 77 winner:  1\n",
      "game 78 winner:  1\n",
      "game 79 winner:  -1\n",
      "game 80 winner:  1\n",
      "game 81 winner:  1\n",
      "game 82 winner:  -1\n",
      "game 83 winner:  -1\n",
      "game 84 winner:  1\n",
      "game 85 winner:  1\n",
      "game 86 winner:  -1\n",
      "game 87 winner:  -1\n",
      "game 88 winner:  1\n",
      "game 89 winner:  -1\n",
      "game 90 winner:  -1\n",
      "game 91 winner:  1\n",
      "game 92 winner:  1\n",
      "game 93 winner:  -1\n",
      "game 94 winner:  -1\n",
      "game 95 winner:  -1\n",
      "game 96 winner:  -1\n",
      "game 97 winner:  -1\n",
      "game 98 winner:  -1\n",
      "game 99 winner:  1\n",
      "game_times: [1.3638179302215576, 1.4004237651824951, 1.3267912864685059, 1.3203880786895752, 1.2375340461730957, 1.2040648460388184, 1.1056828498840332, 1.0061278343200684, 1.0693402290344238, 1.198376178741455, 1.2019028663635254, 1.2446691989898682, 1.3825490474700928, 1.2624151706695557, 1.228119134902954, 1.2642340660095215, 1.2950170040130615, 1.2149178981781006, 1.2423577308654785, 0.9977240562438965, 1.2520031929016113, 1.1229560375213623, 1.1470720767974854, 1.1922192573547363, 0.9720668792724609, 1.1533119678497314, 1.2592103481292725, 1.2256481647491455, 1.2104480266571045, 1.266160011291504, 1.2368650436401367, 1.2420430183410645, 0.9724569320678711, 1.2326509952545166, 1.2599759101867676, 1.2501769065856934, 0.9615960121154785, 1.2677929401397705, 1.2298643589019775, 1.12027907371521, 1.1274418830871582, 1.2638828754425049, 1.083380937576294, 1.2598090171813965, 1.1890738010406494, 1.0608787536621094, 1.239387035369873, 1.024914026260376, 1.074878215789795, 1.2341578006744385, 1.1557629108428955, 1.1799259185791016, 1.2457647323608398, 1.2581548690795898, 0.9340288639068604, 0.9616551399230957, 1.2204198837280273, 1.1967298984527588, 1.170992136001587, 1.1048057079315186, 1.2440588474273682, 1.1035947799682617, 1.0526492595672607, 1.1617600917816162, 1.0281982421875, 1.1610157489776611, 1.2509119510650635, 1.1443920135498047, 1.2230479717254639, 1.2466480731964111, 1.1417582035064697, 1.1556310653686523, 1.219430923461914, 1.1589231491088867, 1.1919059753417969, 1.1877269744873047, 0.9271810054779053, 1.170839786529541, 1.2274770736694336, 1.0854582786560059, 1.1914827823638916, 1.1271498203277588, 1.2281808853149414, 1.0812289714813232, 1.2194457054138184, 1.1896629333496094, 1.236314058303833, 1.2480418682098389, 1.2069151401519775, 1.115462303161621, 1.1963660717010498, 1.1316289901733398, 1.2482779026031494, 1.0209639072418213, 1.1355228424072266, 1.0476489067077637, 1.2476181983947754, 1.2162160873413086, 1.2509970664978027, 1.1531598567962646]\n",
      "q_dict_update_times: [3.4809112548828125e-05, 3.4809112548828125e-05, 3.504753112792969e-05, 3.0994415283203125e-05, 3.075599670410156e-05, 6.29425048828125e-05, 2.384185791015625e-05, 5.1975250244140625e-05, 2.9087066650390625e-05, 3.0994415283203125e-05, 3.3855438232421875e-05, 4.792213439941406e-05, 5.3882598876953125e-05, 3.314018249511719e-05, 3.409385681152344e-05, 3.314018249511719e-05, 3.409385681152344e-05, 2.3603439331054688e-05, 3.4809112548828125e-05, 2.6226043701171875e-05, 2.7894973754882812e-05, 3.0040740966796875e-05, 2.3126602172851562e-05, 2.7894973754882812e-05, 4.291534423828125e-05, 3.3855438232421875e-05, 3.0040740966796875e-05, 3.409385681152344e-05, 3.1948089599609375e-05, 2.384185791015625e-05, 3.2901763916015625e-05, 3.719329833984375e-05, 3.409385681152344e-05, 2.193450927734375e-05, 3.719329833984375e-05, 3.1948089599609375e-05, 2.9087066650390625e-05, 2.6941299438476562e-05, 2.6702880859375e-05, 3.1948089599609375e-05, 2.8848648071289062e-05, 3.62396240234375e-05, 2.5033950805664062e-05, 2.8133392333984375e-05, 3.600120544433594e-05, 3.1948089599609375e-05, 2.9802322387695312e-05, 3.790855407714844e-05, 3.7670135498046875e-05, 2.4080276489257812e-05, 4.220008850097656e-05, 3.409385681152344e-05, 3.314018249511719e-05, 3.1948089599609375e-05, 2.7179718017578125e-05, 3.4809112548828125e-05, 3.0040740966796875e-05, 2.5033950805664062e-05, 2.8848648071289062e-05, 2.6702880859375e-05, 2.9087066650390625e-05, 3.814697265625e-05, 2.9087066650390625e-05, 3.314018249511719e-05, 3.0040740966796875e-05, 3.123283386230469e-05, 3.409385681152344e-05, 4.100799560546875e-05, 3.1948089599609375e-05, 3.1948089599609375e-05, 2.384185791015625e-05, 3.218650817871094e-05, 3.4809112548828125e-05, 2.6941299438476562e-05, 3.1948089599609375e-05, 3.0040740966796875e-05, 3.314018249511719e-05, 2.7894973754882812e-05, 3.409385681152344e-05, 8.296966552734375e-05, 7.82012939453125e-05, 3.6716461181640625e-05, 3.409385681152344e-05, 3.0040740966796875e-05, 3.218650817871094e-05, 2.9087066650390625e-05, 3.600120544433594e-05, 2.5987625122070312e-05, 3.0040740966796875e-05, 2.6941299438476562e-05, 4.00543212890625e-05, 3.4809112548828125e-05, 3.719329833984375e-05, 3.218650817871094e-05]\n",
      "winners: [1, -1, 1, -1, -1, 1, -1, -1, -1, -1, 1, 1, 1, -1, 1, 1, 1, -1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, -1, 1, 1, -1, 1, 1, 1, -1, -1, 1, 1, 1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, -1, 1, -1, 1, 1, 1, -1, 1, -1, 1, -1, -1, 1, 1, -1, 1, 1, -1, -1, 1, 1, -1, -1, 1, -1, -1, 1, 1, -1, -1, -1, -1, -1, -1, 1]\n",
      "Player 1 wins:  54\n",
      "Player -1 wins: 40\n"
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "## Change number of games to simulate here\n",
    "n_games = 100\n",
    "##################################################\n",
    "\n",
    "\n",
    "game_times, q_update_times, winners = big_sim(n_games, agent1, agent2, qtables_to_update=[qtable1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9310411654433076"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#qtable1.q_dict\n",
    "agent1.epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = [2,2,2,2,2]\n",
    "\n",
    "with open('test.pickle', 'wb') as file:\n",
    "    pickle.dump(x, file, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('test.pickle', 'rb') as file:\n",
    "    y = pickle.load(file)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
