{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from helper_func import *\n",
    "import pickle\n",
    "import multiprocessing\n",
    "import keras\n",
    "from multiprocessing import Pool\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, Flatten\n",
    "from collections import deque\n",
    "from keras.activations import relu, linear\n",
    "from keras.losses import mean_squared_error\n",
    "from keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"conv3d_3/Relu:0\", shape=(4, 26, 26, 26, 2), dtype=float32)\n",
      "(4, 26, 26, 26, 2)\n"
     ]
    }
   ],
   "source": [
    "# The inputs are 28x28x28 volumes with a single channel, and the  \n",
    "# batch size is 4  \n",
    "input_shape =(4, 28, 28, 28, 1)\n",
    "x = tf.random.normal(input_shape)\n",
    "y = tf.keras.layers.Conv3D(2, 3, activation='relu', input_shape=input_shape[1:])(x)\n",
    "print(y)\n",
    "print(y.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pentago:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state = None):\n",
    "        \"\"\"Initializes the class reservation\"\"\"\n",
    "        #print('initializing')\n",
    "        \n",
    "        if state == None:\n",
    "            self.state = state = np.zeros((6,6), dtype=np.int)\n",
    "        self.history = []\n",
    "        self.winner = None\n",
    "        self.gameover = False\n",
    "        self.player_turn = 1\n",
    "    \n",
    "    def current_board_state(self):\n",
    "        # need to return a copy or bad stuff happens\n",
    "        return copy.copy(self.state)\n",
    "    \n",
    "    def game_history(self, player, move, cuad, rotatation):\n",
    "        self.history.append((boardstate_to_ideal_key(self.state), ideal_state(self.state), player, move, cuad, rotatation))\n",
    "        #return self.history\n",
    "\n",
    "    def find_winner(self, board_state):\n",
    "        player1_win = False\n",
    "        player_min1_win = False\n",
    "        diagonal1 = board_state.diagonal()\n",
    "        diagonal2 = np.fliplr(board_state).diagonal()\n",
    "        winning_slices =  np.vstack([board_state[1:,:].T, board_state[:-1,:].T, # all columns\n",
    "                              board_state[:,1:], board_state[:,:-1], # all rows\n",
    "                              diagonal1[1:], diagonal1[:-1], # diagonal 1\n",
    "                              diagonal2[1:],diagonal2[1:], # diagonal 2\n",
    "                              board_state.diagonal(offset=1), board_state.diagonal(offset=-1), # diagonal offsets \n",
    "                              np.fliplr(board_state).diagonal(offset=1), np.fliplr(board_state).diagonal(offset=-1)] ) # diagonal offsets\n",
    "        sums = np.dot(winning_slices, np.array([1,1,1,1,1]))\n",
    "        if 5 in sums: player1_win = True\n",
    "        if -5 in sums: player_min1_win = True\n",
    "        if player1_win == True or player_min1_win == True:\n",
    "           # print(\"Player 1 winner?\", player1_win, \"Player -1 winner?\", player_min1_win)\n",
    "            self.gameover = True\n",
    "            if player1_win == True:\n",
    "                self.winner = 1\n",
    "            elif player_min1_win ==True:\n",
    "                self.winner = -1\n",
    "            self.history.append(self.winner)\n",
    "        return \"Win\"\n",
    "\n",
    "    def check_gameover(self):\n",
    "        if not 0 in self.state:\n",
    "              self.gameover = True\n",
    "              #print(\"The game board is full!\")\n",
    "        \n",
    "    def full_move(self, move, cuad, direction, player, dtype=np.int):\n",
    "        if player != self.player_turn:\n",
    "            print( \"error, wrong player turn. No move taken.\")\n",
    "            return 'Error, wrong player turn.'\n",
    "        self.state = fullmove(self.state,move, cuad, direction, player)\n",
    "\n",
    "\n",
    "        self.game_history(move, player, cuad, direction)\n",
    "        self.find_winner(self.state) #return in find_winner if a winner is found\n",
    "        self.check_gameover() #return in check_gameover\n",
    "        if player == 1:\n",
    "            self.player_turn = -1\n",
    "        else:\n",
    "            self.player_turn = 1\n",
    "        #print('Successful Move')\n",
    "        return self.state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "jupyter": {
     "source_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class q_table:\n",
    "\n",
    "    def __init__(self,length=0, games_played=0):\n",
    "        \"\"\"Initializes the class reservation\"\"\"\n",
    "        self.time = datetime.now()\n",
    "        self.length = length\n",
    "        self.q_dict = {}\n",
    "        self.games_played = games_played\n",
    "\n",
    "  #def time(self):\n",
    "    #self.time = time\n",
    "\n",
    "    def length(self):\n",
    "        self.length += 1\n",
    "    #self.length = length  \n",
    "    \n",
    "    def get_q_value(self, boardstate):\n",
    "        return self.q_dict.get(boardstate, (0, 0))\n",
    "    \n",
    "    def update_q_value(self, boardstate, new_val, update_function = None):\n",
    "        q_val, n = self.get_q_value(boardstate) \n",
    "        if update_function:\n",
    "            #print('using custom function')\n",
    "            self.q_dict[boardstate] = update_function(q_val, n, new_val)\n",
    "        else:\n",
    "            self.q_dict[boardstate] = [new_val, n+1]\n",
    "        return self.q_dict[boardstate]\n",
    "    \n",
    "    def update_post_game(self, history, update_fn):\n",
    "        winner = history[-1]\n",
    "        \n",
    "        for boardposition in history[-2::-1]:\n",
    "            key = boardposition[0]\n",
    "            #print(key, winner)\n",
    "            self.update_q_value(key, winner, update_fn)\n",
    "\n",
    "    def update_post_game2(self, history, update_fn, decay_reward = .9):\n",
    "        winner = history[-1]\n",
    "        \n",
    "        for boardposition in history[-2::-1]:\n",
    "            key = boardposition[0]\n",
    "            #print(key, winner)\n",
    "            self.update_q_value(key, winner, update_fn)\n",
    "            winner *= decay_reward\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "class cnn_model:\n",
    "\n",
    "    def __init__(self,list_density=None,lr=0.02, weights = None):\n",
    "        self.model = self.build_model(list_density,lr)\n",
    "        if weights:\n",
    "            self.model.load_weights(weights)\n",
    "\n",
    "    def build_model(self,den,lr):\n",
    "        model = Sequential()\n",
    "        #model.add(tf.keras.Input(shape=(6,6,2,)))\n",
    "        #for layer in den:\n",
    "        model.add(Conv2D(\n",
    "                            filters = 64, \n",
    "                            kernel_size = (3,3),\n",
    "                            strides = (3,3),\n",
    "                            padding = 'valid',\n",
    "                            activation = relu,\n",
    "                            input_shape = (6,6,2)))\n",
    "        model.add(Flatten())\n",
    "        model.add(Dense(256, activation = relu))\n",
    "        model.add(Dense(128, activation = relu))\n",
    "\n",
    "\n",
    "        model.add(Dense(1, activation=linear))\n",
    "        \n",
    "        model.compile(loss=mean_squared_error,optimizer=Adam(lr=lr))\n",
    "        print(model.summary())\n",
    "        return model\n",
    "\n",
    "\n",
    "\n",
    "    def update_model(self,states_batch, q_batch, epochs = 1):\n",
    "\n",
    "        self.model.fit(states_batch,q_batch,epochs = epochs, verbose=1)\n",
    "\n",
    "    def predict_model(self, state_batch):\n",
    "        return self.model.predict_on_batch(state_batch)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_16\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_14 (Conv2D)           (None, 2, 2, 64)          1216      \n",
      "_________________________________________________________________\n",
      "flatten_14 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_40 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_41 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_42 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 100,033\n",
      "Trainable params: 100,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "c = cnn_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6, 6, 2)\n",
      "(1, 1)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[0.06724047]], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([[1,1,1,-1,1,1],[0,0,0,0,0,0],[0,0,0,1,1,0],[0,0,1,-1,-1,0],[0,0,1,-1,1,0],[-1,-1,1,0,0,0]])\n",
    "x = boardstate_to_cnn_input(x)\n",
    "print(x.shape)\n",
    "out= c.model.predict(x.reshape(1,6,6,2))\n",
    "print(out.shape)\n",
    "out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn_agent:\n",
    "    \n",
    "    def __init__(self, nn, player = 1, epsilon = 1, epsilon_decay = .99995, epsilon_min = .5):\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.nn = nn\n",
    "        self.player = player\n",
    "        self.epsilon_min = epsilon_min\n",
    "        \n",
    "            \n",
    "    def get_avail_moves(self,boardstate):\n",
    "        \"\"\"\n",
    "        This method creates a list with available spaces in the board and combination of quadrant and rotation\n",
    "        The input is the board state (6x6) numpy array\n",
    "        \"\"\"\n",
    "        x = np.where(boardstate == 0)\n",
    "        #print(x)\n",
    "        available_positions_for_placement = list(zip(x[0], x[1]))\n",
    "        \n",
    "        # all available positions (p), quadrants(q), rotations(r)\n",
    "        available_moves = [(p,q,r) for p in available_positions_for_placement for q in [1,2,3,4] for r in [-1,1]]\n",
    "        #print(len(available_moves))\n",
    "        return available_moves\n",
    "    \n",
    "    def get_possible_next_boardstates(self, boardstate):\n",
    "        next_possible_boardstates = defaultdict(list)\n",
    "        for move in self.get_avail_moves(boardstate):\n",
    "            possible_boardstate = fullmove(boardstate,*move, self.player)\n",
    "            #print(possible_boardstate)\n",
    "            key = boardstate_to_ideal_key(possible_boardstate)\n",
    "            cnn_input = boardstate_to_cnn_input(possible_boardstate)\n",
    "            #print(cnn_input)\n",
    "            #print(key)\n",
    "            next_possible_boardstates[key].append((cnn_input, move))\n",
    "            \n",
    "        return next_possible_boardstates\n",
    "    \n",
    "    def make_move(self, game):\n",
    "        \n",
    "        # get the current boardstate from the pentago class\n",
    "        boardstate = game.current_board_state()\n",
    "        \n",
    "        # get possible next possible boardstates\n",
    "        #t0 = time.time()\n",
    "        next_possible_boardstates = self.get_possible_next_boardstates(boardstate)\n",
    "        key_list = list(next_possible_boardstates.keys())\n",
    "        #print(\"get possible boardstates\", time.time()-t0)\n",
    "        # determine if to take random move\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            random_bs = random.choice(key_list)\n",
    "            random_mv = next_possible_boardstates[random_bs][0][1] # capture the move needed\n",
    "            \n",
    "            game.full_move(*random_mv,self.player)\n",
    "            \n",
    "        else:\n",
    "            #print(\"not random\", self.player)\n",
    "            #t0 = time.time()\n",
    "            nn_input_boardstate = []\n",
    "            move = []\n",
    "            for k,v in next_possible_boardstates.items():\n",
    "                nn_input_boardstate.append(v[0][0])\n",
    "                #print(v[0][0].shape)\n",
    "                move.append(v[0][1])\n",
    "          \n",
    "            #print(nn_input_boardstate, type(nn_input_boardstate))\n",
    "            #nn_input_batch = np.concatenate(nn_input_boardstate)\n",
    "            nn_input_batch = np.array(nn_input_boardstate)\n",
    "            #print(nn_input_batch, type(nn_input_batch))\n",
    "            #print(nn_input_boardstate)\n",
    "            q_values = self.nn.predict_model(nn_input_batch)\n",
    "            #print(\"get q_values boardstates\", time.time()-t0)\n",
    "\n",
    "            #print(q_values, type(q_values))\n",
    "            #print(\"----\")\n",
    "            q_values *= self.player\n",
    "            #q_values_list = [x*self.player for x in list(q_values)]\n",
    "            #print(q_values_list)\n",
    "            # get random index of a max value\n",
    "            #print('length fo q_values_list = ', len(q_values_list))\n",
    "            max_q = np.argmax(q_values)\n",
    "            #index_of_all_max = [i for i in range(len(q_values)) if q_values[i] == max_q]\n",
    "            #random_max_q_index = random.choice(index_of_all_max)\n",
    "            #print(\"MAX VALUE:\", q_values_list[random_max_q_index])\n",
    "            mv_to_take = move[max_q]\n",
    "            game.full_move(*mv_to_take, self.player)\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay \n",
    "        else:\n",
    "            self.epsilon = self.epsilon_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "class nn_agent_multigame:\n",
    "    \n",
    "    def __init__(self, nn, player = 1, epsilon = 1, epsilon_decay = .99995, epsilon_min = .5):\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.nn = nn\n",
    "        self.player = player\n",
    "        self.epsilon_min = epsilon_min\n",
    "        \n",
    "            \n",
    "    def get_avail_moves(self,boardstate):\n",
    "        \"\"\"\n",
    "        This method creates a list with available spaces in the board and combination of quadrant and rotation\n",
    "        The input is the board state (6x6) numpy array\n",
    "        \"\"\"\n",
    "        x = np.where(boardstate == 0)\n",
    "        #print(x)\n",
    "        available_positions_for_placement = list(zip(x[0], x[1]))\n",
    "        \n",
    "        # all available positions (p), quadrants(q), rotations(r)\n",
    "        available_moves = [(p,q,r) for p in available_positions_for_placement for q in [1,2,3,4] for r in [-1,1]]\n",
    "        #print(len(available_moves))\n",
    "        return available_moves\n",
    "    \n",
    "    def get_possible_next_boardstates(self, boardstate):\n",
    "        next_possible_boardstates = defaultdict(list)\n",
    "        for move in self.get_avail_moves(boardstate):\n",
    "            possible_boardstate = fullmove(boardstate,*move, self.player)\n",
    "            #print(possible_boardstate)\n",
    "            key = boardstate_to_ideal_key(possible_boardstate)\n",
    "            cnn_input = boardstate_to_cnn_input(possible_boardstate)\n",
    "            #print(cnn_input)\n",
    "            #print(key)\n",
    "            next_possible_boardstates[key].append((cnn_input, move))\n",
    "            \n",
    "        return next_possible_boardstates\n",
    "    \n",
    "    def make_move(self, game):\n",
    "        \n",
    "        # get the current boardstate from the pentago class\n",
    "        boardstate = game.current_board_state()\n",
    "        \n",
    "        # get possible next possible boardstates\n",
    "        next_possible_boardstates = self.get_possible_next_boardstates(boardstate)\n",
    "        key_list = list(next_possible_boardstates.keys())\n",
    "        \n",
    "        # determine if to take random move\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            random_bs = random.choice(key_list)\n",
    "            random_mv = next_possible_boardstates[random_bs][0][1] # capture the move needed\n",
    "            \n",
    "            game.full_move(*random_mv,self.player)\n",
    "            \n",
    "        else:\n",
    "            #print(\"not random\", self.player)\n",
    "            nn_input_boardstate = []\n",
    "            move = []\n",
    "            for k,v in next_possible_boardstates.items():\n",
    "                nn_input_boardstate.append(v[0][0])\n",
    "                #print(v[0][0].shape)\n",
    "                move.append(v[0][1])\n",
    "            \n",
    "            \n",
    "            #print(nn_input_boardstate, type(nn_input_boardstate))\n",
    "            #nn_input_batch = np.concatenate(nn_input_boardstate)\n",
    "            nn_input_batch = np.array(nn_input_boardstate)\n",
    "            #print(nn_input_batch, type(nn_input_batch))\n",
    "            #print(nn_input_boardstate)\n",
    "            q_values = self.nn.predict_model(nn_input_batch)\n",
    "            #print(q_values, type(q_values))\n",
    "            #print(\"----\")\n",
    "            q_values *= self.player\n",
    "            #q_values_list = [x*self.player for x in list(q_values)]\n",
    "            #print(q_values_list)\n",
    "            # get random index of a max value\n",
    "            #print('length fo q_values_list = ', len(q_values_list))\n",
    "            max_q = np.argmax(q_values)\n",
    "            #index_of_all_max = [i for i in range(len(q_values)) if q_values[i] == max_q]\n",
    "            #random_max_q_index = random.choice(index_of_all_max)\n",
    "            #print(\"MAX VALUE:\", q_values_list[random_max_q_index])\n",
    "            mv_to_take = move[max_q]\n",
    "            game.full_move(*mv_to_take, self.player)\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay \n",
    "        else:\n",
    "            self.epsilon = self.epsilon_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x = np.array([1,2,3,4,2,1,4])\n",
    "np.argmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('CNN_1_2020-12-05 18_36_18.pickle', 'rb') as file:\n",
    "    nn_1 = pickle.load(file) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn_1.model.save_weights('weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_21\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_19 (Conv2D)           (None, 2, 2, 64)          1216      \n",
      "_________________________________________________________________\n",
      "flatten_19 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_55 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_56 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_57 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 100,033\n",
      "Trainable params: 100,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "nn_2 = cnn_model(weights='weights.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent1 = nn_agent(player = 1,  nn = nn_1, epsilon_min = 0, epsilon_decay = .999, epsilon = 0)\n",
    "agent2 = nn_agent(player = -1,  nn = nn_2, epsilon_min = 0, epsilon = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.2280657291412354\n",
      "28\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('[000000000000000000000000000000000100]',\n",
       "  array([[0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 0, 0, 0],\n",
       "         [0, 0, 0, 1, 0, 0]]),\n",
       "  (0, 0),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000100000000000200]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0, -1,  0,  0]]),\n",
       "  (0, 0),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000201000000000100]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0, -1,  0,  1],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1,  0,  0]]),\n",
       "  (0, 0),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000102000000000201]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1,  0, -1],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0, -1,  0,  1]]),\n",
       "  (0, 0),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000201000100000102]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0, -1,  0,  1],\n",
       "         [ 0,  0,  0,  1,  0,  0],\n",
       "         [ 0,  0,  0,  1,  0, -1]]),\n",
       "  (0, 1),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000112000200000201]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1,  1, -1],\n",
       "         [ 0,  0,  0, -1,  0,  0],\n",
       "         [ 0,  0,  0, -1,  0,  1]]),\n",
       "  (0, 1),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000211000200000112]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0, -1,  1,  1],\n",
       "         [ 0,  0,  0, -1,  0,  0],\n",
       "         [ 0,  0,  0,  1,  1, -1]]),\n",
       "  (0, 1),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000122000101000221]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1, -1, -1],\n",
       "         [ 0,  0,  0,  1,  0,  1],\n",
       "         [ 0,  0,  0, -1, -1,  1]]),\n",
       "  (0, 1),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000221000101001122]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0, -1, -1,  1],\n",
       "         [ 0,  0,  0,  1,  0,  1],\n",
       "         [ 0,  0,  1,  1, -1, -1]]),\n",
       "  (0, 3),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000112000202021211]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1,  1, -1],\n",
       "         [ 0,  0,  0, -1,  0, -1],\n",
       "         [ 0, -1,  1, -1,  1,  1]]),\n",
       "  (0, 4),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000221000101121122]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0, -1, -1,  1],\n",
       "         [ 0,  0,  0,  1,  0,  1],\n",
       "         [ 1, -1,  1,  1, -1, -1]]),\n",
       "  (0, 5),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000112000222121211]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1,  1, -1],\n",
       "         [ 0,  0,  0, -1, -1, -1],\n",
       "         [ 1, -1,  1, -1,  1,  1]]),\n",
       "  (1, 1),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000221001121121122]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0, -1, -1,  1],\n",
       "         [ 0,  0,  1,  1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1, -1]]),\n",
       "  (1, 3),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000112021222121211]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1,  1, -1],\n",
       "         [ 0, -1,  1, -1, -1, -1],\n",
       "         [ 1, -1,  1, -1,  1,  1]]),\n",
       "  (1, 4),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000000221121121121122]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0, -1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1, -1]]),\n",
       "  (1, 5),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000002112121222121211]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0, -1,  1,  1, -1],\n",
       "         [ 1, -1,  1, -1, -1, -1],\n",
       "         [ 1, -1,  1, -1,  1,  1]]),\n",
       "  (2, 3),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000012221121121121122]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  1, -1, -1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1, -1]]),\n",
       "  (2, 4),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000000212112121222121211]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [-1,  1, -1,  1,  1, -1],\n",
       "         [ 1, -1,  1, -1, -1, -1],\n",
       "         [ 1, -1,  1, -1,  1,  1]]),\n",
       "  (2, 5),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000001212221121121121122]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  1],\n",
       "         [-1,  1, -1, -1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1, -1]]),\n",
       "  (3, 0),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000021212112121222121211]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0, -1,  1],\n",
       "         [-1,  1, -1,  1,  1, -1],\n",
       "         [ 1, -1,  1, -1, -1, -1],\n",
       "         [ 1, -1,  1, -1,  1,  1]]),\n",
       "  (3, 1),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000000121212221121121121122]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1, -1,  1],\n",
       "         [-1,  1, -1, -1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1, -1]]),\n",
       "  (3, 2),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000002121212112121222121211]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0, -1,  1, -1,  1],\n",
       "         [-1,  1, -1,  1,  1, -1],\n",
       "         [ 1, -1,  1, -1, -1, -1],\n",
       "         [ 1, -1,  1, -1,  1,  1]]),\n",
       "  (3, 3),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000012121212221121121121122]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  1, -1,  1, -1,  1],\n",
       "         [-1,  1, -1, -1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1, -1]]),\n",
       "  (3, 4),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000000121212211212222121112121]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  0],\n",
       "         [ 1, -1,  1, -1,  1, -1],\n",
       "         [-1,  1,  1, -1,  1, -1],\n",
       "         [-1, -1, -1,  1, -1,  1],\n",
       "         [ 1,  1, -1,  1, -1,  1]]),\n",
       "  (3, 5),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000001212121212221121121121122]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0,  0,  1],\n",
       "         [-1,  1, -1,  1, -1,  1],\n",
       "         [-1,  1, -1, -1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1, -1]]),\n",
       "  (4, 0),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000021212121212112121222121211]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  0, -1,  1],\n",
       "         [-1,  1, -1,  1, -1,  1],\n",
       "         [-1,  1, -1,  1,  1, -1],\n",
       "         [ 1, -1,  1, -1, -1, -1],\n",
       "         [ 1, -1,  1, -1,  1,  1]]),\n",
       "  (4, 1),\n",
       "  -1,\n",
       "  1,\n",
       "  -1),\n",
       " ('[000000000121212121212221121121121122]',\n",
       "  array([[ 0,  0,  0,  0,  0,  0],\n",
       "         [ 0,  0,  0,  1, -1,  1],\n",
       "         [-1,  1, -1,  1, -1,  1],\n",
       "         [-1,  1, -1, -1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1,  1],\n",
       "         [ 1, -1,  1,  1, -1, -1]]),\n",
       "  (4, 2),\n",
       "  1,\n",
       "  1,\n",
       "  -1),\n",
       " -1]"
      ]
     },
     "execution_count": 147,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "g = pentago()\n",
    "while g.gameover == False:\n",
    "    agent1.make_move(g)\n",
    "    if g.gameover == True: break\n",
    "    agent2.make_move(g)\n",
    "    #break\n",
    "\n",
    "#bs = agent1.get_possible_next_boardstates(g.current_board_state())\n",
    "    \n",
    "print(time.time()-t0)\n",
    "print(len(g.history))\n",
    "g.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'> <class 'list'> 32 32\n",
      "(32, 6, 6, 2) (32,)\n",
      "Epoch 1/1\n",
      "32/32 [==============================] - 1s 41ms/step - loss: 0.1705\n"
     ]
    }
   ],
   "source": [
    "g.history[:2]\n",
    "def reward_func(history, decay_factor = .9):\n",
    "    winner = history[-1]\n",
    "    nn_inputs = []\n",
    "    rewards = []\n",
    "    for boardposition in history[-2::-1]:\n",
    "        nn_inputs.append(boardposition[1])\n",
    "        rewards.append(winner)\n",
    "        winner *= decay_factor\n",
    "    return nn_inputs, rewards\n",
    "a = reward_func(g.history)\n",
    "print(type(a[0]), type(a[1]), len(a[0]), len(a[1]))\n",
    "x = np.array([boardstate_to_cnn_input(bs) for bs in a[0]])\n",
    "Y = np.array(a[1])\n",
    "print(x.shape, Y.shape)\n",
    "\n",
    "nn_1.update_model(x,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def little_sim(agents):\n",
    "    agent1, agent2 = agents\n",
    "    g = pentago()\n",
    "    while g.gameover == False:\n",
    "        agent1.make_move(g)\n",
    "        if g.gameover ==True: break\n",
    "        agent2.make_move(g)\n",
    "    #print('gameover.')\n",
    "    return g\n",
    "#little_sim((agent1,agent2))\n",
    "#if __name__ == '__main__':\n",
    "#    with Pool(1) as p:\n",
    "#        game_returns = p.map(little_sim, [(agent1,agent2)]*12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, '9', 0.0), (1, '6', 1607202463.258475), (2, '8', 3214404926.517396), (3, '2', 4821607389.776707), (4, '6', 6428809853.036744), (5, '9', 8036012316.29691), (6, '6', 9643214779.55541), (7, '3', 11250417242.814806), (8, '4', 12857619706.074352), (9, '2', 14464822169.333754)]\n"
     ]
    }
   ],
   "source": [
    "def test(x):\n",
    "    return x, str(time.time())[-1], x*time.time()\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    with Pool(6) as p:\n",
    "        returns = p.map(test, [x for x in range(10)])\n",
    "print(returns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 2, 3, 23, 24, 52, 66]"
      ]
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_returns = [[1,2,3],[23,24,52],[66]]\n",
    "games_list = []\n",
    "for gl in game_returns:\n",
    "    games_list += gl\n",
    "games_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_sim_parallel_nn(n_steps = 1, games_per_step = 32, nn_to_update = [], parallel_threads = 6):\n",
    "    simulation_times = []\n",
    "    nn_update_times = []\n",
    "    winner_list = []\n",
    "    \n",
    "    agent1_epsilon = .5\n",
    "    agent1_epsilon_decay = .99 \n",
    "    agent1_epsilon_min = .1\n",
    "    agent1_nn = nn_to_update[0]\n",
    "    agent1_nn.model.save_weights('nn1_weights.h5')\n",
    "    agent2_epsilon = .5\n",
    "    agent2_epsilon_decay = .995 \n",
    "    agent2_epsilon_min = .2\n",
    "    agent2_nn = nn_to_update[1]\n",
    "    agent2_nn.model.save_weights('nn2_weights.h5')\n",
    "\n",
    "    \n",
    "    for n in range(n_steps):\n",
    "        \n",
    "        #define parallelized process, \n",
    "        def parallel_func(reps):\n",
    "            nn1 = cnn_model(weights = 'nn1_weights.h5')\n",
    "            nn2 = cnn_model(weights = 'nn2_weights.h5')\n",
    "            agent1 = nn_agent(player = 1, nn = nn1, epsilon = agent1_epsilon)\n",
    "            agent2 = nn_agent(player = -1, nn = nn2, epsilon = agent2_epsilon)\n",
    "\n",
    "            game_list = []\n",
    "            \n",
    "            for x in reps:\n",
    "                g = pentago()\n",
    "                while g.gameover == False:\n",
    "                    agent1.make_move(g)\n",
    "                    if g.gameover ==True: break\n",
    "                    agent2.make_move(g)\n",
    "                game_list.append(g)\n",
    "            \n",
    "            return games_list\n",
    "        \n",
    "        \n",
    "        print('game_step', n, end = ' ')\n",
    "        game_start = time.time()\n",
    "        \n",
    "        if __name__ == '__main__':\n",
    "            with Pool(parallel_threads) as p:\n",
    "                game_returns = p.map(parallel_func, [games_per_step//parallel_threads]*games_per_step)\n",
    "        #game_returns = [little_sim((agent1,agent2)) for x in range(games_per_step)] #comment our parallelilization if needed.\n",
    "            \n",
    "        game_times.append(time.time()-game_start)\n",
    "        \n",
    "        # Create single list for iterating\n",
    "        games_list = []\n",
    "        for gl in game_returns:\n",
    "            games_list += gl\n",
    "\n",
    "        player1_winner = 0\n",
    "        player2_winner = 0\n",
    "        # check for winner and create update batch\n",
    "        nn_input_batch = []\n",
    "        rewards_for_batch = []\n",
    "        for game in game_returns:\n",
    "            if game.winner:\n",
    "                if game.winner == 1: player1_winner += 1\n",
    "                else: player2_winner += 1\n",
    "                \n",
    "                #cumulate rewards\n",
    "                boardstates, rewards = reward_func(game.history)\n",
    "                nn_input_batch += [boardstate_to_cnn_input(bs) for bs in boardstates] # add nn_inputs to training list (x)\n",
    "                rewards_for_batch += rewards # add rewards to training list (Y)\n",
    "                \n",
    "        # train the neural network\n",
    "        t0 = time.time()\n",
    "        print(f\"updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\")\n",
    "\n",
    "        agent1_nn.update_model(np.array(nn_input_batch), np.array(rewards_for_batch))\n",
    "        agent1_nn.model.save_weights(nn1_weights)\n",
    "        agent2_nn.update_model(np.array(nn_input_batch), np.array(rewards_for_batch))\n",
    "        agent2_nn.model.save_weights(nn2_weights)\n",
    "        nn_update_times.append(time.time() - t0)\n",
    "        \n",
    "        if agent1.epsilon > agent1.epsilon_min: agent1.epsilon *= agent1.epsilon_decay\n",
    "        if agent2.epsilon > agent2.epsilon_min: agent2.epsilon *= agent2.epsilon_decay\n",
    "        print(\"player 1 wins:\", player1_winner)\n",
    "        print(\"player 2 wins:\", player2_winner)\n",
    "        print(\"parallelized batch took\", game_times[-1], \"seconds.\")\n",
    "        print(\"neural network update:\", nn_update_times[-1], \"seconds.\")\n",
    "        \n",
    "    # end of simulation runs, save q_table(s) to disk\n",
    "    nn_num = 1\n",
    "    time_str = str(datetime.now())[:19].replace(':','_')\n",
    "    for nn in nn_to_update:\n",
    "        with open(f'pCNN_{nn_num}_'+time_str+'.pickle', 'wb') as file:\n",
    "            pickle.dump(nn, file, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "        nn_num += 1\n",
    "    \n",
    "    return game_times\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_24\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_22 (Conv2D)           (None, 2, 2, 64)          1216      \n",
      "_________________________________________________________________\n",
      "flatten_22 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_64 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_65 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_66 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 100,033\n",
      "Trainable params: 100,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n",
      "Model: \"sequential_25\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d_23 (Conv2D)           (None, 2, 2, 64)          1216      \n",
      "_________________________________________________________________\n",
      "flatten_23 (Flatten)         (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "dense_67 (Dense)             (None, 256)               65792     \n",
      "_________________________________________________________________\n",
      "dense_68 (Dense)             (None, 128)               32896     \n",
      "_________________________________________________________________\n",
      "dense_69 (Dense)             (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 100,033\n",
      "Trainable params: 100,033\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "# Note you will overwrite this q_table and agents if you run this cell again.    Verify you won't lose your data!\n",
    "#with open('decay_q_table1_2020-11-29 12_09_00.pickle', 'rb') as file:\n",
    "#    qtable1 =  pickle.load(file)\n",
    "nn_1 = cnn_model()\n",
    "nn_2 = cnn_model()\n",
    "agent1 = nn_agent(player = 1,  nn = nn_1, epsilon_min = .02, epsilon = 1)\n",
    "agent2 = nn_agent(player = -1,  nn = nn_1, epsilon_min = .15, epsilon = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_step 0 "
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "Can't pickle local object 'big_sim_parallel_nn.<locals>.parallel_func'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-164-f6e38259730e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mbig_sim_parallel_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgames_per_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_to_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn_1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-162-7c994f541d75>\u001b[0m in \u001b[0;36mbig_sim_parallel_nn\u001b[0;34m(n_steps, games_per_step, nn_to_update, parallel_threads)\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m'__main__'\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m             \u001b[0;32mwith\u001b[0m \u001b[0mPool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_threads\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m                 \u001b[0mgame_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparallel_func\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mgames_per_step\u001b[0m\u001b[0;34m//\u001b[0m\u001b[0mparallel_threads\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mgames_per_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m         \u001b[0;31m#game_returns = [little_sim((agent1,agent2)) for x in range(games_per_step)] #comment our parallelilization if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mmap\u001b[0;34m(self, func, iterable, chunksize)\u001b[0m\n\u001b[1;32m    266\u001b[0m         \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mlist\u001b[0m \u001b[0mthat\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0mreturned\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    267\u001b[0m         '''\n\u001b[0;32m--> 268\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_map_async\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmapstar\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    269\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    270\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstarmap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchunksize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_set\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/pool.py\u001b[0m in \u001b[0;36m_handle_tasks\u001b[0;34m(taskqueue, put, outqueue, pool, cache)\u001b[0m\n\u001b[1;32m    429\u001b[0m                         \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    430\u001b[0m                     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 431\u001b[0;31m                         \u001b[0mput\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtask\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    432\u001b[0m                     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m                         \u001b[0mjob\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0midx\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtask\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/connection.py\u001b[0m in \u001b[0;36msend\u001b[0;34m(self, obj)\u001b[0m\n\u001b[1;32m    204\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    205\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_writable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 206\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    207\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    208\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mrecv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlength\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/multiprocessing/reduction.py\u001b[0m in \u001b[0;36mdumps\u001b[0;34m(cls, obj, protocol)\u001b[0m\n\u001b[1;32m     49\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mdumps\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcls\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBytesIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 51\u001b[0;31m         \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mprotocol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     52\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     53\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: Can't pickle local object 'big_sim_parallel_nn.<locals>.parallel_func'"
     ]
    }
   ],
   "source": [
    "big_sim_parallel_nn(n_steps=1, games_per_step=32, nn_to_update=[nn_1, nn_2], parallel_threads=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent2.epsilon"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_step 0 updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\n",
      "Epoch 1/1\n",
      "707/707 [==============================] - 0s 177us/step - loss: 0.2039\n",
      "player 1 wins: 19\n",
      "player 2 wins: 10\n",
      "parallelized batch took 56.845152139663696 seconds.\n",
      "neural network update: 0.12768101692199707 seconds.\n",
      "game_step 1 updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\n",
      "Epoch 1/1\n",
      "850/850 [==============================] - 0s 169us/step - loss: 0.1874\n",
      "player 1 wins: 19\n",
      "player 2 wins: 12\n",
      "parallelized batch took 60.10708212852478 seconds.\n",
      "neural network update: 0.145676851272583 seconds.\n",
      "game_step 2 updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\n",
      "Epoch 1/1\n",
      "775/775 [==============================] - 0s 181us/step - loss: 0.1691\n",
      "player 1 wins: 25\n",
      "player 2 wins: 6\n",
      "parallelized batch took 57.84349822998047 seconds.\n",
      "neural network update: 0.14233803749084473 seconds.\n",
      "game_step 3 updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\n",
      "Epoch 1/1\n",
      "703/703 [==============================] - 0s 170us/step - loss: 0.1518\n",
      "player 1 wins: 27\n",
      "player 2 wins: 4\n",
      "parallelized batch took 53.924663066864014 seconds.\n",
      "neural network update: 0.12165617942810059 seconds.\n",
      "game_step 4 updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\n",
      "Epoch 1/1\n",
      "786/786 [==============================] - 0s 173us/step - loss: 0.1730\n",
      "player 1 wins: 22\n",
      "player 2 wins: 8\n",
      "parallelized batch took 59.06911897659302 seconds.\n",
      "neural network update: 0.13857316970825195 seconds.\n",
      "game_step 5 updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\n",
      "Epoch 1/1\n",
      "690/690 [==============================] - 0s 185us/step - loss: 0.1656\n",
      "player 1 wins: 27\n",
      "player 2 wins: 5\n",
      "parallelized batch took 52.32254195213318 seconds.\n",
      "neural network update: 0.12985706329345703 seconds.\n",
      "game_step 6 updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\n",
      "Epoch 1/1\n",
      "738/738 [==============================] - 0s 172us/step - loss: 0.1409\n",
      "player 1 wins: 28\n",
      "player 2 wins: 4\n",
      "parallelized batch took 56.269805908203125 seconds.\n",
      "neural network update: 0.12915802001953125 seconds.\n",
      "game_step 7 updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\n",
      "Epoch 1/1\n",
      "702/702 [==============================] - 0s 173us/step - loss: 0.1137\n",
      "player 1 wins: 30\n",
      "player 2 wins: 2\n",
      "parallelized batch took 54.090025186538696 seconds.\n",
      "neural network update: 0.12353682518005371 seconds.\n",
      "game_step 8 updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\n",
      "Epoch 1/1\n",
      "604/604 [==============================] - 0s 177us/step - loss: 0.1453\n",
      "player 1 wins: 26\n",
      "player 2 wins: 3\n",
      "parallelized batch took 55.296996116638184 seconds.\n",
      "neural network update: 0.10882306098937988 seconds.\n",
      "game_step 9 updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\n",
      "Epoch 1/1\n",
      "662/662 [==============================] - 0s 184us/step - loss: 0.1812\n",
      "player 1 wins: 24\n",
      "player 2 wins: 6\n",
      "parallelized batch took 55.20333790779114 seconds.\n",
      "neural network update: 0.12394857406616211 seconds.\n",
      "game_step 0 updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\n",
      "Epoch 1/1\n",
      "726/726 [==============================] - 0s 287us/step - loss: 0.1280\n",
      "player 1 wins: 29\n",
      "player 2 wins: 3\n",
      "parallelized batch took 56.31709814071655 seconds.\n",
      "neural network update: 0.21080493927001953 seconds.\n",
      "game_step 1 updating with {len(nn_input_batch)}, {len(rewards_for_batch)} training batch.\n",
      "Epoch 1/1\n",
      "735/735 [==============================] - 0s 213us/step - loss: 0.1598\n",
      "player 1 wins: 27\n",
      "player 2 wins: 5\n",
      "parallelized batch took 57.0644428730011 seconds.\n",
      "neural network update: 0.1589491367340088 seconds.\n",
      "game_step 2 "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-77-c7d4034dc925>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mtime0\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mbig_sim_parallel_nn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0magent2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgames_per_step\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m32\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnn_to_update\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnn_1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparallel_threads\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m6\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mtime0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'seconds.'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-09663b3ae365>\u001b[0m in \u001b[0;36mbig_sim_parallel_nn\u001b[0;34m(agent1, agent2, n_steps, games_per_step, nn_to_update, parallel_threads)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#    with Pool(parallel_threads) as p:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#        game_returns = p.map(little_sim, [(agent1,agent2)]*games_per_step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mgame_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlittle_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgames_per_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#comment our parallelilization if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#games_in_progress = [pentago() for g in games_per_step]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-09663b3ae365>\u001b[0m in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     11\u001b[0m         \u001b[0;31m#    with Pool(parallel_threads) as p:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m         \u001b[0;31m#        game_returns = p.map(little_sim, [(agent1,agent2)]*games_per_step)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m         \u001b[0mgame_returns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mlittle_sim\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0magent1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0magent2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgames_per_step\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m#comment our parallelilization if needed.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m         \u001b[0;31m#games_in_progress = [pentago() for g in games_per_step]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-73-b1ada5c448c2>\u001b[0m in \u001b[0;36mlittle_sim\u001b[0;34m(agents)\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0mg\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpentago\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mwhile\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgameover\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m         \u001b[0magent1\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgameover\u001b[0m \u001b[0;34m==\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mbreak\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m         \u001b[0magent2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_move\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-21d6d3f3cb59>\u001b[0m in \u001b[0;36mmake_move\u001b[0;34m(self, game)\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m         \u001b[0;31m# get possible next possible boardstates\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m         \u001b[0mnext_possible_boardstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_possible_next_boardstates\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboardstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m         \u001b[0mkey_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnext_possible_boardstates\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-52-21d6d3f3cb59>\u001b[0m in \u001b[0;36mget_possible_next_boardstates\u001b[0;34m(self, boardstate)\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0mnext_possible_boardstates\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdefaultdict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     27\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mmove\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_avail_moves\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboardstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 28\u001b[0;31m             \u001b[0mpossible_boardstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfullmove\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboardstate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mmove\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplayer\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     29\u001b[0m             \u001b[0;31m#print(possible_boardstate)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m             \u001b[0mkey\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mboardstate_to_ideal_key\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpossible_boardstate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Fall2020MIDS/w251_pentago/helper_func.py\u001b[0m in \u001b[0;36mfullmove\u001b[0;34m(boardstate, placement_location, quadrant, rotation, marble)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     44\u001b[0m     \u001b[0mnew_boardstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mplace_marble\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mboardstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplacement_location\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmarble\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 45\u001b[0;31m     \u001b[0mnew_boardstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrotate_quadrant\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnew_boardstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mquadrant\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     46\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mnew_boardstate\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/Fall2020MIDS/w251_pentago/helper_func.py\u001b[0m in \u001b[0;36mrotate_quadrant\u001b[0;34m(boardstate, quadrant, rotation)\u001b[0m\n\u001b[1;32m     35\u001b[0m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnew_boardstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;31m# slice out quadrant\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     36\u001b[0m     \u001b[0;31m#print(q)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 37\u001b[0;31m     \u001b[0mq\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrot90\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mq\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrotation\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     38\u001b[0m     \u001b[0;31m#print(q)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m     \u001b[0mnew_boardstate\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mc1\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mc2\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mq\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mrot90\u001b[0;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36mrot90\u001b[0;34m(m, k, axes)\u001b[0m\n\u001b[1;32m    131\u001b[0m     \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0masanyarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 133\u001b[0;31m     \u001b[0;32mif\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mabsolute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0maxes\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mm\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndim\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    134\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Axes must be different.\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "## Change number of games to simulate here\n",
    "#_games = 10000\n",
    "##################################################\n",
    "\n",
    "time0 = time.time()\n",
    "for x in range(20):\n",
    "    big_sim_parallel_nn(agent1, agent2, n_steps=10, games_per_step=32, nn_to_update=[nn_1], parallel_threads=6)\n",
    "print(time.time()-time0, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.593888888888888"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "59738/60/60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5444204"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qtable1.q_dict)\n",
    "#agent1.epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = [2,2,2,2,2]\n",
    "\n",
    "with open('test.pickle', 'wb') as file:\n",
    "    pickle.dump(x, file, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('test.pickle', 'rb') as file:\n",
    "    y = pickle.load(file)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = []\n",
    "for k,v in qtable1.q_dict.items():\n",
    "    ns.append(v[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5444199,       3,       1,       0,       0,       0,       0,\n",
       "              0,       0,       1]),\n",
       " array([1.000000e+00, 1.797250e+04, 3.594400e+04, 5.391550e+04,\n",
       "        7.188700e+04, 8.985850e+04, 1.078300e+05, 1.258015e+05,\n",
       "        1.437730e+05, 1.617445e+05, 1.797160e+05]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(np.array(ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "153873\n",
      "67959\n",
      "46602\n",
      "33784\n",
      "12230\n"
     ]
    }
   ],
   "source": [
    "print(len([x for x in ns if x != 1]))\n",
    "print(len([x for x in ns if x > 2]))\n",
    "print(len([x for x in ns if x > 3]))\n",
    "print(len([x for x in ns if x > 4]))\n",
    "print(len([x for x in ns if x > 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[120020100111022211102201112221201221] (0.5, 1)\n",
      "[020011100211022012102201112221201221] (0.5, 1)\n",
      "[002011202211010012102201112201201221] (0.5, 1)\n",
      "[002011202211010012210201010201122221] (0.5, 1)\n",
      "[020011100211022012210001010201122221] (0.5, 1)\n",
      "[110020112001200220022012002010111221] (0.5, 1)\n"
     ]
    }
   ],
   "source": [
    "i = 0\n",
    "for k,v in qtable1.q_dict.items():\n",
    "    print(k,v)\n",
    "    i += 1\n",
    "    if i > 5: break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([94371,     6,     0,     0,     0,     0,     0,     0,     0,\n",
       "            1]),\n",
       " array([2.00000e+00, 1.15380e+04, 2.30740e+04, 3.46100e+04, 4.61460e+04,\n",
       "        5.76820e+04, 6.92180e+04, 8.07540e+04, 9.22900e+04, 1.03826e+05,\n",
       "        1.15362e+05]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram([x for x in ns if x != 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
