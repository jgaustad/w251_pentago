{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from datetime import datetime\n",
    "import time\n",
    "from collections import defaultdict\n",
    "from helper_func import *\n",
    "import pickle\n",
    "import multiprocessing\n",
    "from multiprocessing import Pool\n",
    "\n",
    "\n",
    "\n",
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class pentago:\n",
    "    \"\"\"\n",
    "    \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, state = None):\n",
    "        \"\"\"Initializes the class reservation\"\"\"\n",
    "        #print('initializing')\n",
    "        \n",
    "        if state == None:\n",
    "            self.state = state = np.zeros((6,6), dtype=np.int)\n",
    "        self.history = []\n",
    "        self.winner = None\n",
    "        self.gameover = False\n",
    "        self.player_turn = 1\n",
    "    \n",
    "    def current_board_state(self):\n",
    "        # need to return a copy or bad stuff happens\n",
    "        return copy.copy(self.state)\n",
    "    \n",
    "    def game_history(self, player, move, cuad, rotatation):\n",
    "        self.history.append((boardstate_to_ideal_key(self.state), player, move, cuad, rotatation))\n",
    "        #return self.history\n",
    "\n",
    "    def find_winner(self, board_state):\n",
    "        player1_win = False\n",
    "        player_min1_win = False\n",
    "        diagonal1 = board_state.diagonal()\n",
    "        diagonal2 = np.fliplr(board_state).diagonal()\n",
    "        winning_slices =  np.vstack([board_state[1:,:].T, board_state[:-1,:].T, # all columns\n",
    "                              board_state[:,1:], board_state[:,:-1], # all rows\n",
    "                              diagonal1[1:], diagonal1[:-1], # diagonal 1\n",
    "                              diagonal2[1:],diagonal2[1:], # diagonal 2\n",
    "                              board_state.diagonal(offset=1), board_state.diagonal(offset=-1), # diagonal offsets \n",
    "                              np.fliplr(board_state).diagonal(offset=1), np.fliplr(board_state).diagonal(offset=-1)] ) # diagonal offsets\n",
    "        sums = np.dot(winning_slices, np.array([1,1,1,1,1]))\n",
    "        if 5 in sums: player1_win = True\n",
    "        if -5 in sums: player_min1_win = True\n",
    "        if player1_win == True or player_min1_win == True:\n",
    "           # print(\"Player 1 winner?\", player1_win, \"Player -1 winner?\", player_min1_win)\n",
    "            self.gameover = True\n",
    "            if player1_win == True:\n",
    "                self.winner = 1\n",
    "            elif player_min1_win ==True:\n",
    "                self.winner = -1\n",
    "            self.history.append(self.winner)\n",
    "        return \"Win\"\n",
    "\n",
    "    def check_gameover(self):\n",
    "        if not 0 in self.state:\n",
    "              self.gameover = True\n",
    "              #print(\"The game board is full!\")\n",
    "        \n",
    "    def full_move(self, move, cuad, direction, player, dtype=np.int):\n",
    "        if player != self.player_turn:\n",
    "            print( \"error, wrong player turn. No move taken.\")\n",
    "            return 'Error, wrong player turn.'\n",
    "        self.state = fullmove(self.state,move, cuad, direction, player)\n",
    "\n",
    "\n",
    "        self.game_history(move, player, cuad, direction)\n",
    "        self.find_winner(self.state) #return in find_winner if a winner is found\n",
    "        self.check_gameover() #return in check_gameover\n",
    "        if player == 1:\n",
    "            self.player_turn = -1\n",
    "        else:\n",
    "            self.player_turn = 1\n",
    "        #print('Successful Move')\n",
    "        return self.state\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class q_table:\n",
    "\n",
    "    def __init__(self,length=0, games_played=0):\n",
    "        \"\"\"Initializes the class reservation\"\"\"\n",
    "        self.time = datetime.now()\n",
    "        self.length = length\n",
    "        self.q_dict = {}\n",
    "        self.games_played = games_played\n",
    "\n",
    "  #def time(self):\n",
    "    #self.time = time\n",
    "\n",
    "    def length(self):\n",
    "        self.length += 1\n",
    "    #self.length = length  \n",
    "    \n",
    "    def get_q_value(self, boardstate):\n",
    "        return self.q_dict.get(boardstate, (0, 0))\n",
    "    \n",
    "    def update_q_value(self, boardstate, new_val, update_function = None):\n",
    "        q_val, n = self.get_q_value(boardstate) \n",
    "        if update_function:\n",
    "            #print('using custom function')\n",
    "            self.q_dict[boardstate] = update_function(q_val, n, new_val)\n",
    "        else:\n",
    "            self.q_dict[boardstate] = [new_val, n+1]\n",
    "        return self.q_dict[boardstate]\n",
    "    \n",
    "    def update_post_game(self, history, update_fn):\n",
    "        winner = history[-1]\n",
    "        \n",
    "        for boardposition in history[-2::-1]:\n",
    "            key = boardposition[0]\n",
    "            #print(key, winner)\n",
    "            self.update_q_value(key, winner, update_fn)\n",
    "\n",
    "    def update_post_game2(self, history, update_fn, decay_reward = .9):\n",
    "        winner = history[-1]\n",
    "        \n",
    "        for boardposition in history[-2::-1]:\n",
    "            key = boardposition[0]\n",
    "            #print(key, winner)\n",
    "            self.update_q_value(key, winner, update_fn)\n",
    "            winner *= decay_reward\n",
    "\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def my_func(q, n, nn):\n",
    "    #print('here',q, n, nn, 'end')\n",
    "    #q, n = cv\n",
    "    return (q*n+nn)/(n+1), n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dampen_func(q, n, nn):\n",
    "    #print('here',q, n, nn, 'end')\n",
    "    #q, n = cv\n",
    "    return (q*(n+1)+nn)/(n+2), n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "class qtable_agent:\n",
    "    \n",
    "    def __init__(self, player = 1, epsilon = 1, epsilon_decay = .99995, epsilon_min = .5, q_table = q_table()):\n",
    "        self.epsilon = epsilon\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.q_table = q_table\n",
    "        self.player = player\n",
    "        self.epsilon_min = epsilon_min\n",
    "        \n",
    "            \n",
    "    def get_avail_moves(self,boardstate):\n",
    "        \"\"\"\n",
    "        This method creates a list with available spaces in the board and combination of quadrant and rotation\n",
    "        The input is the board state (6x6) numpy array\n",
    "        \"\"\"\n",
    "        x = np.where(boardstate == 0)\n",
    "        #print(x)\n",
    "        available_positions_for_placement = list(zip(x[0], x[1]))\n",
    "        \n",
    "        # all available positions (p), quadrants(q), rotations(r)\n",
    "        available_moves = [(p,q,r) for p in available_positions_for_placement for q in [1,2,3,4] for r in [-1,1]]\n",
    "        #print(len(available_moves))\n",
    "        return available_moves\n",
    "    \n",
    "    def get_possible_next_boardstates(self, boardstate):\n",
    "        next_possible_boardstates = defaultdict(list)\n",
    "        for move in self.get_avail_moves(boardstate):\n",
    "            possible_boardstate = fullmove(boardstate,*move, self.player)\n",
    "            key = boardstate_to_ideal_key(possible_boardstate)\n",
    "            #print(key)\n",
    "            next_possible_boardstates[key].append(move)\n",
    "            \n",
    "        return next_possible_boardstates\n",
    "    \n",
    "    def make_move(self, game):\n",
    "        \n",
    "        # get the current boardstate from the pentago class\n",
    "        boardstate = game.current_board_state()\n",
    "        \n",
    "        # get possible next possible boardstates\n",
    "        next_possible_boardstates = self.get_possible_next_boardstates(boardstate)\n",
    "        key_list = list(next_possible_boardstates.keys())\n",
    "        \n",
    "        # determine if to take random move\n",
    "        if np.random.rand() < self.epsilon:\n",
    "            random_bs = random.choice(key_list)\n",
    "            random_mv = next_possible_boardstates[random_bs][0]\n",
    "            \n",
    "            game.full_move(*random_mv,self.player)\n",
    "            \n",
    "        else:\n",
    "            #print(\"not random\", self.player)\n",
    "            q_values_list = [self.q_table.get_q_value(bs)[0]*self.player for bs in key_list] # *player flips the q's for -1 player to allow max calc\n",
    "            #print(q_values_list)\n",
    "            \n",
    "            # get random index of a max value\n",
    "            max_q = (max(q_values_list))\n",
    "            index_of_all_max = [i for i in range(len(q_values_list)) if q_values_list[i] == max_q]\n",
    "            random_max_q_index = random.choice(index_of_all_max)\n",
    "            \n",
    "            mv_to_take = next_possible_boardstates[key_list[random_max_q_index]][0]\n",
    "            game.full_move(*mv_to_take, self.player)\n",
    "        \n",
    "        if self.epsilon > self.epsilon_min:\n",
    "            self.epsilon *= self.epsilon_decay \n",
    "        else:\n",
    "            self.epsilon = self.epsilon_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def little_sim(agents):\n",
    "    agent1, agent2 = agents\n",
    "    g = pentago()\n",
    "    while g.gameover == False:\n",
    "        agent1.make_move(g)\n",
    "        if g.gameover ==True: break\n",
    "        agent2.make_move(g)\n",
    "    #print('gameover.')\n",
    "    return g\n",
    "        \n",
    "#t0 = time.time()\n",
    "#if __name__ == '__main__':\n",
    "#    with Pool(6) as p:\n",
    "#        game_returns = p.map(little_sim, [(agent1,agent2)]*500)\n",
    "#time.time() -t0\n",
    "\n",
    "#6 on 500 is 222sec\n",
    "\n",
    "#6 100 is 79sec\n",
    "#4 100 is 67sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def little_sim(agents):\n",
    "    agent1, agent2 = agents\n",
    "    g = pentago()\n",
    "    while g.gameover == False:\n",
    "        agent1.make_move(g)\n",
    "        if g.gameover ==True: break\n",
    "        agent2.make_move(g)\n",
    "    #print('gameover.')\n",
    "    return g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "game_returns[1].winner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def big_sim_parallel(agent1, agent2, n_steps = 1, games_per_step = 500, qtables_to_update = [], parallel_threads = 6,  update_cadence = 1):\n",
    "    game_times = []\n",
    "    q_dict_update_times = []\n",
    "    winner_list = []\n",
    "    \n",
    "    for n in range(n_steps):\n",
    "        print('game_step', n, end = ' ')\n",
    "        game_start = time.time()\n",
    "        \n",
    "        if __name__ == '__main__':\n",
    "            with Pool(parallel_threads) as p:\n",
    "                game_returns = p.map(little_sim, [(agent1,agent2)]*games_per_step)\n",
    "\n",
    "            \n",
    "        game_times.append(time.time()-game_start)\n",
    "        \n",
    "        player1_winner = 0\n",
    "        player2_winner = 0\n",
    "        # check for winner and update q_table(s)\n",
    "        for game in game_returns:\n",
    "            if game.winner:\n",
    "                if game.winner == 1: player1_winner += 1\n",
    "                else: player2_winner += 1\n",
    "                \n",
    "                for q_tab in qtables_to_update:\n",
    "                    q_tab.update_post_game2(game.history, dampen_func)\n",
    "        print(\"player 1 wins:\", player1_winner)\n",
    "        print(\"player 2 wins:\", player2_winner)\n",
    "        print(\"parallelized batch took\", game_times[-1], \"seconds.\")\n",
    "        \n",
    "    # end of simulation runs, save q_table(s) to disk\n",
    "    qt_num = 1\n",
    "    time_str = str(datetime.now())[:19].replace(':','_')\n",
    "    for q_tab in qtables_to_update:\n",
    "        with open(f'decay_q_table{qt_num}_'+time_str+'.pickle', 'wb') as file:\n",
    "            pickle.dump(q_tab, file, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "        qt_num += 1\n",
    "    \n",
    "    return game_times\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Note you will overwrite this q_table and agents if you run this cell again.    Verify you won't lose your data!\n",
    "with open('decay_q_table1_2020-11-29 00_08_54.pickle', 'rb') as file:\n",
    "    qtable1 =  pickle.load(file)\n",
    "agent1 = qtable_agent(player = 1,  q_table=qtable1, epsilon_min = .05, epsilon = .5)\n",
    "agent2 = qtable_agent(player = -1, q_table=qtable1, epsilon_min = .05, epsilon = .5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "game_step 0 player 1 wins: 257\n",
      "player 2 wins: 220\n",
      "parallelized batch took 365.7337212562561 seconds.\n",
      "game_step 1 player 1 wins: 285\n",
      "player 2 wins: 192\n",
      "parallelized batch took 257.35220193862915 seconds.\n",
      "game_step 2 player 1 wins: 286\n",
      "player 2 wins: 195\n",
      "parallelized batch took 241.08361506462097 seconds.\n",
      "game_step 3 player 1 wins: 272\n",
      "player 2 wins: 209\n",
      "parallelized batch took 247.9022159576416 seconds.\n",
      "game_step 4 player 1 wins: 271\n",
      "player 2 wins: 208\n",
      "parallelized batch took 274.16999101638794 seconds.\n",
      "game_step 5 player 1 wins: 274\n",
      "player 2 wins: 200\n",
      "parallelized batch took 243.872652053833 seconds.\n",
      "game_step 6 player 1 wins: 276\n",
      "player 2 wins: 203\n",
      "parallelized batch took 252.4220209121704 seconds.\n",
      "game_step 7 player 1 wins: 275\n",
      "player 2 wins: 208\n",
      "parallelized batch took 245.13045501708984 seconds.\n",
      "game_step 8 player 1 wins: 288\n",
      "player 2 wins: 186\n",
      "parallelized batch took 266.3476507663727 seconds.\n",
      "game_step 9 player 1 wins: 269\n",
      "player 2 wins: 207\n",
      "parallelized batch took 257.8820481300354 seconds.\n",
      "game_step 10 player 1 wins: 260\n",
      "player 2 wins: 213\n",
      "parallelized batch took 266.68523693084717 seconds.\n",
      "game_step 11 player 1 wins: 279\n",
      "player 2 wins: 200\n",
      "parallelized batch took 261.2622790336609 seconds.\n",
      "game_step 12 player 1 wins: 279\n",
      "player 2 wins: 198\n",
      "parallelized batch took 277.7065851688385 seconds.\n",
      "game_step 13 player 1 wins: 276\n",
      "player 2 wins: 207\n",
      "parallelized batch took 266.6158800125122 seconds.\n",
      "game_step 14 player 1 wins: 268\n",
      "player 2 wins: 209\n",
      "parallelized batch took 265.7478151321411 seconds.\n",
      "game_step 15 player 1 wins: 290\n",
      "player 2 wins: 189\n",
      "parallelized batch took 274.0883960723877 seconds.\n",
      "game_step 16 player 1 wins: 270\n",
      "player 2 wins: 213\n",
      "parallelized batch took 267.42215609550476 seconds.\n",
      "game_step 17 player 1 wins: 292\n",
      "player 2 wins: 193\n",
      "parallelized batch took 261.10678005218506 seconds.\n",
      "game_step 18 player 1 wins: 294\n",
      "player 2 wins: 192\n",
      "parallelized batch took 255.6798369884491 seconds.\n",
      "game_step 19 player 1 wins: 262\n",
      "player 2 wins: 210\n",
      "parallelized batch took 260.3816981315613 seconds.\n",
      "game_step 0 player 1 wins: 274\n",
      "player 2 wins: 200\n",
      "parallelized batch took 249.13849711418152 seconds.\n",
      "game_step 1 player 1 wins: 282\n",
      "player 2 wins: 200\n",
      "parallelized batch took 241.7287027835846 seconds.\n",
      "game_step 2 player 1 wins: 303\n",
      "player 2 wins: 180\n",
      "parallelized batch took 242.48633909225464 seconds.\n",
      "game_step 3 player 1 wins: 266\n",
      "player 2 wins: 209\n",
      "parallelized batch took 241.6682550907135 seconds.\n",
      "game_step 4 player 1 wins: 281\n",
      "player 2 wins: 190\n",
      "parallelized batch took 242.00725984573364 seconds.\n",
      "game_step 5 player 1 wins: 272\n",
      "player 2 wins: 205\n",
      "parallelized batch took 238.51046013832092 seconds.\n",
      "game_step 6 player 1 wins: 263\n",
      "player 2 wins: 211\n",
      "parallelized batch took 237.2573697566986 seconds.\n",
      "game_step 7 player 1 wins: 288\n",
      "player 2 wins: 198\n",
      "parallelized batch took 243.92772603034973 seconds.\n",
      "game_step 8 player 1 wins: 287\n",
      "player 2 wins: 187\n",
      "parallelized batch took 240.33529686927795 seconds.\n",
      "game_step 9 player 1 wins: 278\n",
      "player 2 wins: 198\n",
      "parallelized batch took 243.28520703315735 seconds.\n",
      "game_step 10 player 1 wins: 281\n",
      "player 2 wins: 189\n",
      "parallelized batch took 242.81846499443054 seconds.\n",
      "game_step 11 player 1 wins: 272\n",
      "player 2 wins: 208\n",
      "parallelized batch took 241.5624442100525 seconds.\n",
      "game_step 12 player 1 wins: 270\n",
      "player 2 wins: 207\n",
      "parallelized batch took 240.56254172325134 seconds.\n",
      "game_step 13 player 1 wins: 289\n",
      "player 2 wins: 184\n",
      "parallelized batch took 240.56625699996948 seconds.\n",
      "game_step 14 player 1 wins: 259\n",
      "player 2 wins: 218\n",
      "parallelized batch took 239.9158489704132 seconds.\n",
      "game_step 15 player 1 wins: 285\n",
      "player 2 wins: 189\n",
      "parallelized batch took 243.27090001106262 seconds.\n",
      "game_step 16 player 1 wins: 285\n",
      "player 2 wins: 188\n",
      "parallelized batch took 240.36940789222717 seconds.\n",
      "game_step 17 player 1 wins: 280\n",
      "player 2 wins: 196\n",
      "parallelized batch took 239.54107999801636 seconds.\n",
      "game_step 18 player 1 wins: 286\n",
      "player 2 wins: 187\n",
      "parallelized batch took 251.31053280830383 seconds.\n",
      "game_step 19 player 1 wins: 295\n",
      "player 2 wins: 180\n",
      "parallelized batch took 241.0693221092224 seconds.\n",
      "game_step 0 player 1 wins: 291\n",
      "player 2 wins: 178\n",
      "parallelized batch took 250.80690622329712 seconds.\n",
      "game_step 1 player 1 wins: 268\n",
      "player 2 wins: 205\n",
      "parallelized batch took 240.59606409072876 seconds.\n",
      "game_step 2 player 1 wins: 301\n",
      "player 2 wins: 178\n",
      "parallelized batch took 243.61120796203613 seconds.\n",
      "game_step 3 player 1 wins: 280\n",
      "player 2 wins: 202\n",
      "parallelized batch took 236.94769310951233 seconds.\n",
      "game_step 4 player 1 wins: 272\n",
      "player 2 wins: 205\n",
      "parallelized batch took 245.9358263015747 seconds.\n",
      "game_step 5 player 1 wins: 273\n",
      "player 2 wins: 206\n",
      "parallelized batch took 238.543692111969 seconds.\n",
      "game_step 6 player 1 wins: 278\n",
      "player 2 wins: 201\n",
      "parallelized batch took 243.99294710159302 seconds.\n",
      "game_step 7 player 1 wins: 273\n",
      "player 2 wins: 201\n",
      "parallelized batch took 343.50582003593445 seconds.\n",
      "game_step 8 player 1 wins: 287\n",
      "player 2 wins: 185\n",
      "parallelized batch took 352.96396493911743 seconds.\n",
      "game_step 9 player 1 wins: 273\n",
      "player 2 wins: 200\n",
      "parallelized batch took 341.06623697280884 seconds.\n",
      "game_step 10 player 1 wins: 280\n",
      "player 2 wins: 197\n",
      "parallelized batch took 341.5623962879181 seconds.\n",
      "game_step 11 player 1 wins: 263\n",
      "player 2 wins: 210\n",
      "parallelized batch took 346.44335675239563 seconds.\n",
      "game_step 12 player 1 wins: 300\n",
      "player 2 wins: 183\n",
      "parallelized batch took 356.6796929836273 seconds.\n",
      "game_step 13 player 1 wins: 276\n",
      "player 2 wins: 198\n",
      "parallelized batch took 422.696409702301 seconds.\n",
      "game_step 14 player 1 wins: 285\n",
      "player 2 wins: 195\n",
      "parallelized batch took 484.02405881881714 seconds.\n",
      "game_step 15 player 1 wins: 282\n",
      "player 2 wins: 195\n",
      "parallelized batch took 460.2101089954376 seconds.\n",
      "game_step 16 player 1 wins: 281\n",
      "player 2 wins: 196\n",
      "parallelized batch took 450.1358528137207 seconds.\n",
      "game_step 17 player 1 wins: 280\n",
      "player 2 wins: 195\n",
      "parallelized batch took 462.89619517326355 seconds.\n",
      "game_step 18 player 1 wins: 304\n",
      "player 2 wins: 179\n",
      "parallelized batch took 449.54795002937317 seconds.\n",
      "game_step 19 player 1 wins: 287\n",
      "player 2 wins: 192\n",
      "parallelized batch took 459.4398808479309 seconds.\n",
      "game_step 0 "
     ]
    }
   ],
   "source": [
    "##################################################\n",
    "## Change number of games to simulate here\n",
    "n_games = 10000\n",
    "##################################################\n",
    "\n",
    "time0 = time.time()\n",
    "for x in range(20):\n",
    "    game_t = big_sim_parallel(agent1, agent2, n_steps=20, qtables_to_update=[qtable1])\n",
    "print(time.time()-time0, 'seconds.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.593888888888888"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "59738/60/60\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3136962"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(qtable1.q_dict)\n",
    "#agent1.epsilon"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "x = [2,2,2,2,2]\n",
    "\n",
    "with open('test.pickle', 'wb') as file:\n",
    "    pickle.dump(x, file, protocol = pickle.HIGHEST_PROTOCOL)\n",
    "    \n",
    "with open('test.pickle', 'rb') as file:\n",
    "    y = pickle.load(file)\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "ns = []\n",
    "for k,v in qtable1.q_dict.items():\n",
    "    ns.append(v[1])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([3136955,       6,       0,       0,       0,       0,       0,\n",
       "              0,       0,       1]),\n",
       " array([1.000000e+00, 1.153710e+04, 2.307320e+04, 3.460930e+04,\n",
       "        4.614540e+04, 5.768150e+04, 6.921760e+04, 8.075370e+04,\n",
       "        9.228980e+04, 1.038259e+05, 1.153620e+05]))"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram(np.array(ns))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "94378\n",
      "39381\n",
      "27224\n",
      "19200\n",
      "6851\n"
     ]
    }
   ],
   "source": [
    "print(len([x for x in ns if x != 1]))\n",
    "print(len([x for x in ns if x > 2]))\n",
    "print(len([x for x in ns if x > 3]))\n",
    "print(len([x for x in ns if x > 4]))\n",
    "print(len([x for x in ns if x > 10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([94371,     6,     0,     0,     0,     0,     0,     0,     0,\n",
       "            1]),\n",
       " array([2.00000e+00, 1.15380e+04, 2.30740e+04, 3.46100e+04, 4.61460e+04,\n",
       "        5.76820e+04, 6.92180e+04, 8.07540e+04, 9.22900e+04, 1.03826e+05,\n",
       "        1.15362e+05]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.histogram([x for x in ns if x != 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
